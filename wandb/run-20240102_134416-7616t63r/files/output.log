Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-large and are newly initialized: ['classifier.out_proj.bias', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.


Map:  63%|██████████████████████████████████████                      | 25000/39389 [00:03<00:01, 7713.97 examples/s]
  0%|                                                                                       | 0/4000 [00:00<?, ?it/s]You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.

























































































































































































































































































 10%|███████▌                                                                   | 400/4000 [09:34<1:26:23,  1.44s/it]






  accuracy = load_metric("accuracy")█████████████████████████████████████████████████| 25/25 [00:12<00:00,  2.29it/s]
Traceback (most recent call last):
  File "/data/2_data_server/nlp-04/lost_technology/test.py", line 98, in <module>
    trainer.train()
  File "/home/nlp-04/anaconda3/envs/heck/lib/python3.11/site-packages/transformers/trainer.py", line 1555, in train
    return inner_training_loop(
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/nlp-04/anaconda3/envs/heck/lib/python3.11/site-packages/transformers/trainer.py", line 1929, in _inner_training_loop
    self._maybe_log_save_evaluate(tr_loss, model, trial, epoch, ignore_keys_for_eval)
  File "/home/nlp-04/anaconda3/envs/heck/lib/python3.11/site-packages/transformers/trainer.py", line 2256, in _maybe_log_save_evaluate
    metrics = self.evaluate(ignore_keys=ignore_keys_for_eval)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/nlp-04/anaconda3/envs/heck/lib/python3.11/site-packages/transformers/trainer.py", line 2994, in evaluate
    self.log(output.metrics)
  File "/home/nlp-04/anaconda3/envs/heck/lib/python3.11/site-packages/transformers/trainer.py", line 2598, in log
    self.control = self.callback_handler.on_log(self.args, self.state, self.control, logs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/nlp-04/anaconda3/envs/heck/lib/python3.11/site-packages/transformers/trainer_callback.py", line 399, in on_log
    return self.call_event("on_log", args, state, control, logs=logs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/nlp-04/anaconda3/envs/heck/lib/python3.11/site-packages/transformers/trainer_callback.py", line 406, in call_event
    result = getattr(callback, event)(
             ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/nlp-04/anaconda3/envs/heck/lib/python3.11/site-packages/transformers/integrations.py", line 803, in on_log
    self._wandb.log({**logs, "train/global_step": state.global_step})
  File "/home/nlp-04/anaconda3/envs/heck/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 420, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/nlp-04/anaconda3/envs/heck/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 371, in wrapper_fn
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/nlp-04/anaconda3/envs/heck/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 361, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/nlp-04/anaconda3/envs/heck/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 1820, in log
    self._log(data=data, step=step, commit=commit)
  File "/home/nlp-04/anaconda3/envs/heck/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 1595, in _log
    self._partial_history_callback(data, step, commit)
  File "/home/nlp-04/anaconda3/envs/heck/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 1467, in _partial_history_callback
    self._backend.interface.publish_partial_history(
  File "/home/nlp-04/anaconda3/envs/heck/lib/python3.11/site-packages/wandb/sdk/interface/interface.py", line 561, in publish_partial_history
    item.value_json = json_dumps_safer_history(v)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/nlp-04/anaconda3/envs/heck/lib/python3.11/site-packages/wandb/util.py", line 839, in json_dumps_safer_history
    return dumps(obj, cls=WandBHistoryJSONEncoder, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/nlp-04/anaconda3/envs/heck/lib/python3.11/json/__init__.py", line 238, in dumps
    **kw).encode(obj)
          ^^^^^^^^^^^
  File "/home/nlp-04/anaconda3/envs/heck/lib/python3.11/json/encoder.py", line 200, in encode
    chunks = self.iterencode(o, _one_shot=True)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/nlp-04/anaconda3/envs/heck/lib/python3.11/json/encoder.py", line 258, in iterencode
    return _iterencode(o, 0)
           ^^^^^^^^^^^^^^^^^
  File "/home/nlp-04/anaconda3/envs/heck/lib/python3.11/site-packages/wandb/util.py", line 804, in default
    return json.JSONEncoder.default(self, obj)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/nlp-04/anaconda3/envs/heck/lib/python3.11/json/encoder.py", line 180, in default
    raise TypeError(f'Object of type {o.__class__.__name__} '
TypeError: Object of type F1 is not JSON serializable